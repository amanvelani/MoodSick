{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5928ba5-a1f0-4321-bdd1-b01dae910658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8b7cc7-c80d-48b5-b93b-a871769493b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps') if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248f8521-78c0-4860-bbde-e70f62ede034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = pd.read_csv('../data/gztan/features_30_sec.csv')\n",
    "display(csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d034a18-965f-4344-84dc-383167204ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetType(Enum):\n",
    "    TRAIN = 0\n",
    "    TEST = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4c51f8-986a-472c-bc64-faeed249e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, csv_path: str, save_crops: bool=False):\n",
    "        self.csv_path = Path(csv_path)\n",
    "        \n",
    "        self.cropped_dir = self.csv_path.parent / 'cropped'\n",
    "        if not self.cropped_dir.exists():\n",
    "            self.cropped_dir.mkdir(exist_ok=False)\n",
    "            print(\"Created cropped dir.\")\n",
    "        \n",
    "        self.csv = pd.read_csv(csv_path)\n",
    "\n",
    "        # Add a column for the filepath.\n",
    "        self.csv['im_path'] = self.csv.apply(lambda x: x.filename.strip('wav').replace('.', '') + '.png', axis=1)\n",
    "        \n",
    "        self.genre_ix = self._make_ix_splits()\n",
    "        self.genre_statistics = self.preprocess_image_and_compute_stats(save_crops)\n",
    "\n",
    "    def _make_ix_splits(self):\n",
    "        genre_dict = dict()\n",
    "        for genre in self.csv.label.unique():\n",
    "            index = self.csv.loc[self.csv.label == genre, :].index\n",
    "            # shuffle the indices.\n",
    "            shuffled = np.random.permutation(index)\n",
    "            split = int(len(shuffled) * 0.8)\n",
    "            genre_dict[genre] = {DatasetType.TRAIN: shuffled[:split], DatasetType.TEST: shuffled[split:]}\n",
    "        return genre_dict\n",
    "\n",
    "    def preprocess_image_and_compute_stats(self, save_crops=False):\n",
    "\n",
    "        def _save_images(genre, im_paths, path_to_save):\n",
    "            for im_path in im_paths:\n",
    "                joined_path = self.csv_path.parent / 'images_original' / genre / im_path\n",
    "                if not joined_path.exists():\n",
    "                    continue\n",
    "                \n",
    "                with Image.open(joined_path, 'r') as image:\n",
    "                    # Convert from CMYK to RGB.\n",
    "                    image = image.convert('RGB')\n",
    "                    # Crop the image.\n",
    "                    # (224, 352)\n",
    "                    im = image.crop(box=(44, 29, 396, 253))\n",
    "                    im_name = 'cropped_' + im_path\n",
    "                    im.save(path_to_save / im_name)\n",
    "\n",
    "        def _compute_stats(im_path):\n",
    "            images = list(im_path.glob('*.png'))\n",
    "            means = []\n",
    "            stds = []\n",
    "            for image in images:\n",
    "                with Image.open(image, 'r') as im:\n",
    "                    # Convert the cropped images to ndarrays\n",
    "                    arr = np.asarray(im)\n",
    "                    # Compute channel-wise means\n",
    "                    means.append(np.mean(arr, axis=(0, 1), keepdims=True))\n",
    "\n",
    "                    # Compute the channel-wise\n",
    "                    stds.append(np.std(arr, axis=(0, 1), keepdims=True))\n",
    "\n",
    "            return (\n",
    "                np.mean(np.concatenate(means, axis=0), axis=0).flatten(),\n",
    "                np.mean(np.concatenate(stds, axis=0), axis=0).flatten()\n",
    "            )\n",
    "\n",
    "        genre_stats = dict()\n",
    "        \n",
    "        for genre, genre_dict in self.genre_ix.items():\n",
    "            train_df = self.csv.loc[genre_dict[DatasetType.TRAIN]]\n",
    "            test_df = self.csv.loc[genre_dict[DatasetType.TEST]]\n",
    "\n",
    "            print(f\"genre: {genre}, train: {train_df.shape}, test: {test_df.shape}\")\n",
    "\n",
    "            genre_dir = self.cropped_dir / genre\n",
    "            if not genre_dir.exists():\n",
    "                genre_dir.mkdir(exist_ok=False)\n",
    "            \n",
    "            train_dir = genre_dir / 'train'\n",
    "            if not train_dir.exists():\n",
    "                train_dir.mkdir(exist_ok=False)\n",
    "                \n",
    "            test_dir = genre_dir / 'test'\n",
    "            if not test_dir.exists():\n",
    "                test_dir.mkdir(exist_ok=False)\n",
    "                \n",
    "            if save_crops:\n",
    "                _save_images(genre, train_df.im_path, train_dir)\n",
    "                _save_images(genre, test_df.im_path, test_dir)\n",
    "\n",
    "            genre_mean, genre_std = _compute_stats(train_dir)\n",
    "            genre_stats[genre] = {'mean': genre_mean, 'std': genre_std}\n",
    "\n",
    "        return genre_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406fa4a0-5ac9-46c7-a3ce-64d59fc91ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre: blues, train: (80, 61), test: (20, 61)\n",
      "genre: classical, train: (80, 61), test: (20, 61)\n",
      "genre: country, train: (80, 61), test: (20, 61)\n",
      "genre: disco, train: (80, 61), test: (20, 61)\n",
      "genre: hiphop, train: (80, 61), test: (20, 61)\n",
      "genre: jazz, train: (80, 61), test: (20, 61)\n",
      "genre: metal, train: (80, 61), test: (20, 61)\n",
      "genre: pop, train: (80, 61), test: (20, 61)\n",
      "genre: reggae, train: (80, 61), test: (20, 61)\n",
      "genre: rock, train: (80, 61), test: (20, 61)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor('../data/gztan/features_30_sec.csv', save_crops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74537aea-2d23-4bef-86b0-a5affeb74259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderDataset(Dataset):\n",
    "    def __init__(self, dset: DatasetType, dir: Path, preprocessor: Preprocessor):\n",
    "        self.dset = dset\n",
    "        self.dir = dir\n",
    "        self.preprocessor = preprocessor\n",
    "        self.transforms = self._setup_transforms()\n",
    "        self.data = self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        rows = []\n",
    "        for genre in self.preprocessor.genre_statistics.keys():\n",
    "            subdir = self.dir / genre / 'train' if self.dset == DatasetType.TRAIN else self.dir / genre / 'test'\n",
    "            pngs = list(subdir.glob('*.png'))\n",
    "            for png_file in pngs:\n",
    "                rows.append((genre, png_file))\n",
    "        \n",
    "        return pd.DataFrame(rows, columns=['genre', 'filename'])\n",
    "\n",
    "    def _setup_transforms(self):\n",
    "        transforms_dict = dict()\n",
    "        for genre, tsfm in self.preprocessor.genre_statistics.items():\n",
    "            transforms_dict[genre] = transforms.Compose([\n",
    "                transforms.PILToTensor(),\n",
    "                transforms.ConvertImageDtype(torch.float),\n",
    "                transforms.Normalize(mean=tsfm['mean'], std=tsfm['std'])\n",
    "            ])\n",
    "        return transforms_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        im_name = self.data.loc[i, 'filename']\n",
    "        genre = self.data.loc[i, 'genre']\n",
    "        \n",
    "        with Image.open(im_name, 'r') as im:\n",
    "            im = self.transforms[genre](im)\n",
    "\n",
    "        # X and Y are the same.\n",
    "        return im, im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3e359e-7846-4dab-aaba-211bbbd1790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = AutoencoderDataset(DatasetType.TRAIN, preprocessor.cropped_dir, preprocessor)\n",
    "train_loader = DataLoader(train_dset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b7ef12-b01d-4f99-bd17-4d730fe2bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cccae926-5868-4cdf-bdba-57f50adff201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 224, 352]), torch.Size([8, 3, 224, 352]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size(), Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7e72ed-7f11-40cc-87a5-177b5dc01ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalEncoder(nn.Module):\n",
    "    def __init__(self, im_size: int, config: dict):\n",
    "        super(MultiModalEncoder, self).__init__()\n",
    "        self.im_size = im_size\n",
    "        self.config = config\n",
    "        self.encoder = self._make_encoder()\n",
    "        self.decoder = self._make_decoder()\n",
    "\n",
    "    def _conv_block(self, config: dict):\n",
    "        layers = list()\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=config['in'], \n",
    "                out_channels=config['out'], \n",
    "                padding=config['padding'], \n",
    "                kernel_size=config['ksize'],\n",
    "                stride=config['stride'], \n",
    "                bias=False\n",
    "            )\n",
    "        )\n",
    "        if config['act'] == 'relu':\n",
    "            layers.append(nn.ReLU(inplace=False))\n",
    "        elif config['act'] == 'lrelu':\n",
    "            layers.append(nn.LeakyReLU(negative_slope=0.01, inplace=False))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _deconv_block(self, config: dict):\n",
    "        layers = list()\n",
    "        layers.append(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=config['in'], \n",
    "                out_channels=config['out'], \n",
    "                padding=config['padding'], \n",
    "                kernel_size=config['ksize'],\n",
    "                output_padding=config['output_padding'] if 'output_padding' in config else 0,\n",
    "                stride=config['stride'], \n",
    "                bias=False\n",
    "            )\n",
    "        )\n",
    "        if config['act'] == 'relu':\n",
    "            layers.append(nn.ReLU(inplace=False))\n",
    "        elif config['act'] == 'lrelu':\n",
    "            layers.append(nn.LeakyReLU(negative_slope=0.01, inplace=False))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _linear(self, config: dict):\n",
    "        layers = list()\n",
    "        layers.append(\n",
    "            nn.Linear(\n",
    "                in_features=config['in'], \n",
    "                out_features=config['out'],\n",
    "                bias=config['bias']\n",
    "            )\n",
    "        )\n",
    "        if 'act' in config:\n",
    "            if config['act'] == 'relu':\n",
    "                layers.append(nn.ReLU(inplace=False))\n",
    "            elif config['act'] == 'lrelu':\n",
    "                layers.append(nn.LeakyReLU(negative_slope=0.01, inplace=False))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _flatten(self):\n",
    "        return nn.Sequential(nn.Flatten())\n",
    "\n",
    "    def _reshape(self, config: dict):\n",
    "        return nn.Sequential(nn.Unflatten(dim=1, unflattened_size=config['out']))\n",
    "\n",
    "    def _make_encoder(self):\n",
    "        encoder_config = self.config['encoder']\n",
    "        encoder = nn.ModuleList()\n",
    "        \n",
    "        for layer_type, config in encoder_config.items():\n",
    "            if 'conv' in layer_type:\n",
    "                encoder.append(self._conv_block(config))\n",
    "            elif 'linear' in layer_type:\n",
    "                encoder.append(self._linear(config))\n",
    "            elif 'flatten' in layer_type:\n",
    "                encoder.append(self._flatten())\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def _make_decoder(self):\n",
    "        decoder_config = self.config['decoder']\n",
    "        decoder = nn.ModuleList()\n",
    "\n",
    "        for layer_type, config in decoder_config.items():\n",
    "            if 'linear' in layer_type:\n",
    "                decoder.append(self._linear(config))\n",
    "            elif 'reshape' in layer_type:\n",
    "                decoder.append(self._reshape(config))\n",
    "            elif 'deconv' in layer_type:\n",
    "                decoder.append(self._deconv_block(config))\n",
    "\n",
    "        return decoder\n",
    "    \n",
    "    def forward(self, im):\n",
    "        \n",
    "        # Pass through the encoder.\n",
    "        for module in self.encoder:\n",
    "            im = module(im)\n",
    "\n",
    "        # Obtain a reference to the bottleneck.\n",
    "        x = im\n",
    "\n",
    "        # Pass through the decoder.\n",
    "        for module in self.decoder:\n",
    "            im = module(im)\n",
    "        \n",
    "        return x, im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a67d627-103b-46f7-a71d-5603072ab1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = OrderedDict()\n",
    "\n",
    "# (336, 210, 3) -> (168, 105, 8)\n",
    "encoder_config['conv1'] = {'in': 3, 'out': 8, 'ksize': 5, 'padding': 1, 'stride': 2, 'act': 'relu'}\n",
    "# (168, 105, 8) -> (168, 105, 8)\n",
    "encoder_config['conv2'] = {'in': 8, 'out': 8, 'ksize': 3, 'padding': 1, 'stride': 1, 'act': 'relu'}\n",
    "# (168, 105, 8) -> (84, 52, 16)\n",
    "encoder_config['conv3'] = {'in': 8, 'out': 16, 'ksize': 3, 'padding': 1, 'stride': 2, 'act': 'relu'}\n",
    "# (84, 52, 16) -> (84, 52, 16)\n",
    "encoder_config['conv4'] = {'in': 16, 'out': 16, 'ksize': 3, 'padding': 1, 'stride': 1, 'act': 'relu'}\n",
    "# (84, 52, 32) -> (42, 26, 32)\n",
    "encoder_config['conv5'] = {'in': 16, 'out': 32, 'ksize': 3, 'padding': 1, 'stride': 2, 'act': 'relu'}\n",
    "# (42, 26, 32) -> (42, 26, 32)\n",
    "encoder_config['conv6'] = {'in': 32, 'out': 32, 'ksize': 3, 'padding': 1, 'stride': 1, 'act': 'relu'}\n",
    "# (42, 26, 32) -> (21, 13, 64)\n",
    "encoder_config['conv7'] = {'in': 32, 'out': 64, 'ksize': 3, 'padding': 1, 'stride': 2, 'act': 'relu'}\n",
    "# (21, 13, 64) -> (21, 13, 64)\n",
    "encoder_config['conv8'] = {'in': 64, 'out': 64, 'ksize': 3, 'padding': 1, 'stride': 1, 'act': 'relu'}\n",
    "# (21, 13, 64) -> (10, 6, 128)\n",
    "encoder_config['conv9'] = {'in': 64, 'out': 128, 'ksize': 3, 'padding': 1, 'stride': 2, 'act': 'relu'}\n",
    "# (10, 6, 128) -> (10, 6, 128)\n",
    "encoder_config['conv10'] = {'in': 128, 'out': 128, 'ksize': 3, 'padding': 1, 'stride': 1, 'act': 'relu'}\n",
    "# (10, 6, 128) -> (7680,)\n",
    "encoder_config['flatten'] = {}\n",
    "# (7680,) -> (512,)\n",
    "encoder_config['linear1'] = {'in': 9856, 'out': 512, 'bias': True, 'act': 'relu'}\n",
    "\n",
    "\n",
    "## Decoder config\n",
    "decoder_config = OrderedDict()\n",
    "\n",
    "# torch.Size([8, 3, 220, 336])\n",
    "# torch.Size([8, 8, 109, 167])\n",
    "# torch.Size([8, 8, 109, 167])\n",
    "# torch.Size([8, 16, 55, 84])\n",
    "# torch.Size([8, 16, 55, 84])\n",
    "# torch.Size([8, 32, 28, 42])\n",
    "# torch.Size([8, 32, 28, 42])\n",
    "# torch.Size([8, 64, 14, 21])\n",
    "# torch.Size([8, 64, 14, 21])\n",
    "# torch.Size([8, 128, 7, 11])\n",
    "# torch.Size([8, 128, 7, 11])\n",
    "# torch.Size([8, 9856])\n",
    "\n",
    "decoder_config['linear1'] = {'in': 512, 'out': 9856, 'bias': True, 'acr': 'relu'}\n",
    "decoder_config['reshape'] = {'in': 9856, 'out': (128, 7, 11)}\n",
    "decoder_config['deconv1'] = {'in': 128, 'out': 128, 'ksize': 3, 'stride': 1, 'padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv2'] = {'in': 128, 'out': 64, 'ksize': 3, 'stride': 2, 'padding': 1, 'output_padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv3'] = {'in': 64, 'out': 64, 'ksize': 3, 'stride': 1, 'padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv4'] = {'in': 64, 'out': 32, 'ksize': 3, 'stride': 2, 'padding': 1, 'output_padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv5'] = {'in': 32, 'out': 32, 'ksize': 3, 'stride': 1, 'padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv6'] = {'in': 32, 'out': 16, 'ksize': 3, 'stride': 2, 'padding': 1, 'output_padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv7'] = {'in': 16, 'out': 16, 'ksize': 3, 'stride': 1, 'padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv8'] = {'in': 16, 'out': 8, 'ksize': 3, 'stride': 2, 'padding': 1, 'output_padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv9'] = {'in': 8, 'out': 8, 'ksize': 3, 'stride': 1, 'padding': 1, 'act': 'relu'}\n",
    "decoder_config['deconv10'] = {'in': 8, 'out': 3, 'ksize': 3, 'stride': 2, 'padding': 1, 'output_padding': 1, 'act': 'relu'}\n",
    "\n",
    "sample_config = {\n",
    "    'encoder': encoder_config,\n",
    "    'decoder': decoder_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ec74e2a-567b-44ac-b9ff-3fe2082999a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc = MultiModalEncoder(im_size=1, config=sample_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8919f570-0a46-475e-8685-908c2680d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc = autoenc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aa83012-cb01-4a02-97ba-8c85eb9b4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692400\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in autoenc.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afaa0177-3b48-4ecd-899f-4147f330c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(autoenc.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea281769-f965-45eb-8afe-b4cac98f9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, dataloader):\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "\n",
    "    for ix, (X, Y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        z, y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, Y)\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2b4fa08-842d-4408-bd54-15c1459dd2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.40295109152793884\n",
      "Loss: 0.5041136145591736\n",
      "Loss: 0.3473391830921173\n",
      "Loss: 0.406434029340744\n",
      "Loss: 0.4231855273246765\n",
      "Loss: 0.4638163447380066\n",
      "Loss: 0.3942844867706299\n",
      "Loss: 0.33832645416259766\n",
      "Loss: 0.473519504070282\n",
      "Loss: 0.5593042969703674\n",
      "Loss: 0.45632055401802063\n",
      "Loss: 0.4605395197868347\n",
      "Loss: 0.5319695472717285\n",
      "Loss: 0.37657880783081055\n",
      "Loss: 0.5240647196769714\n",
      "Loss: 0.5458301901817322\n",
      "Loss: 0.49803802371025085\n",
      "Loss: 0.4092603921890259\n",
      "Loss: 0.4578917622566223\n",
      "Loss: 0.38769233226776123\n",
      "Loss: 0.35605019330978394\n",
      "Loss: 0.4764402508735657\n",
      "Loss: 0.5691649317741394\n",
      "Loss: 0.4800168573856354\n",
      "Loss: 0.5159707069396973\n",
      "Loss: 0.40255218744277954\n",
      "Loss: 0.41760018467903137\n",
      "Loss: 0.3906107246875763\n",
      "Loss: 0.532140851020813\n",
      "Loss: 0.4584776759147644\n",
      "Loss: 0.4789537787437439\n",
      "Loss: 0.5543557405471802\n",
      "Loss: 0.45214441418647766\n",
      "Loss: 0.42188596725463867\n",
      "Loss: 0.5485376715660095\n",
      "Loss: 0.4799860417842865\n",
      "Loss: 0.4641628861427307\n",
      "Loss: 0.40561196208000183\n",
      "Loss: 0.587681770324707\n",
      "Loss: 0.4482971429824829\n",
      "Loss: 0.5355638265609741\n",
      "Loss: 0.6262721419334412\n",
      "Loss: 0.48609793186187744\n",
      "Loss: 0.4764772653579712\n",
      "Loss: 0.7653448581695557\n",
      "Loss: 0.4707053601741791\n",
      "Loss: 0.555446207523346\n",
      "Loss: 0.48542168736457825\n",
      "Loss: 0.49870777130126953\n",
      "Loss: 0.3906446099281311\n",
      "Loss: 0.4683704376220703\n",
      "Loss: 0.40739771723747253\n",
      "Loss: 0.3834296464920044\n",
      "Loss: 0.3447154760360718\n",
      "Loss: 0.4974454939365387\n",
      "Loss: 0.43051984906196594\n",
      "Loss: 0.49808889627456665\n",
      "Loss: 0.7024984359741211\n",
      "Loss: 0.619908332824707\n",
      "Loss: 0.4736446440219879\n",
      "Loss: 0.5167163610458374\n",
      "Loss: 0.6151358485221863\n",
      "Loss: 0.39873605966567993\n",
      "Loss: 0.383835107088089\n",
      "Loss: 0.4708988666534424\n",
      "Loss: 0.3859653174877167\n",
      "Loss: 0.4704071879386902\n",
      "Loss: 0.5605736374855042\n",
      "Loss: 0.628648579120636\n",
      "Loss: 0.4212602972984314\n",
      "Loss: 0.38194578886032104\n",
      "Loss: 0.36984187364578247\n",
      "Loss: 0.4237051010131836\n",
      "Loss: 0.5102256536483765\n",
      "Loss: 0.3907732367515564\n",
      "Loss: 0.39502111077308655\n",
      "Loss: 0.5625942349433899\n",
      "Loss: 0.5859060287475586\n",
      "Loss: 0.451462984085083\n",
      "Loss: 0.5298709869384766\n",
      "Loss: 0.5009095072746277\n",
      "Loss: 0.625542163848877\n",
      "Loss: 0.3649415969848633\n",
      "Loss: 0.384822815656662\n",
      "Loss: 0.5892755389213562\n",
      "Loss: 0.4987114667892456\n",
      "Loss: 0.36919063329696655\n",
      "Loss: 0.4259128272533417\n",
      "Loss: 0.3225170969963074\n",
      "Loss: 0.5285418629646301\n",
      "Loss: 0.5968162417411804\n",
      "Loss: 0.4214826226234436\n",
      "Loss: 0.325976699590683\n",
      "Loss: 0.38694822788238525\n",
      "Loss: 0.40561822056770325\n",
      "Loss: 0.4573434293270111\n",
      "Loss: 0.3987777531147003\n",
      "Loss: 0.4368245601654053\n",
      "Loss: 0.4882880449295044\n",
      "Loss: 0.44349971413612366\n",
      "Loss: 0.45680469274520874\n",
      "Loss: 0.49986767768859863\n",
      "Loss: 0.4087226390838623\n",
      "Loss: 0.3906692862510681\n",
      "Loss: 0.48363256454467773\n",
      "Loss: 0.48249614238739014\n",
      "Loss: 0.4449683129787445\n",
      "Loss: 0.578307032585144\n",
      "Loss: 0.36472204327583313\n",
      "Loss: 0.48587363958358765\n",
      "Loss: 0.4759261906147003\n",
      "Loss: 0.47284504771232605\n",
      "Loss: 0.6368342041969299\n",
      "Loss: 0.47055917978286743\n",
      "Loss: 0.41758981347084045\n",
      "Loss: 0.4774068295955658\n",
      "Loss: 0.38801565766334534\n",
      "Loss: 0.4090741276741028\n",
      "Loss: 0.6070587635040283\n",
      "Loss: 0.5302062630653381\n",
      "Loss: 0.42725270986557007\n"
     ]
    }
   ],
   "source": [
    "train(autoenc, optimizer, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085e66d-17dc-44b7-b87c-7233fbaea198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
